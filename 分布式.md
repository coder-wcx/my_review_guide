分布式:
    1.分布式状态:
        成功
        失败
        超时
    2.数据一致性
        强一致性 任何时刻任何用户或节点都可以读到最新的数据 难实现
        单调一致性 任何时刻，任何用户一旦读到某个数据在某次更新后的值，这个用户不会再读到比这个值更旧的值
        会话一致性 任何用户在某一次会话内一旦读到某个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更旧的值
        最终一致性 最终一致性要求一旦更新成功，各个副本上的数据最终将达到完全一致的状态，但达到完全一致状态所需要的时间不能保障
        弱一致性 一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。
    
    分布式事务解决方案:
        1.两阶段提交
        包含一个中心化协调者节点，还有n个参与者节点
            第一阶段:协调者询问所有的参与者是否可以提交事务，参与者投票
            第二阶段:协调者通过投票结果来判定是否通过提交事务，只要有一个参与者选择放弃事务，则失败
        两阶段提交涉及需要两轮交互 4 个消息“prepare”、“vote-commit”、“global-commit”、“确认 global-commit”。
        如果有参与者响应过慢，那么会拖慢整个流程 单点问题，阻塞问题
        2.mvcc 多版本并发控制multi version concurrent control 不懂怎么实现???
        3.三阶段提交
            改良了两阶段提交
                引入超时机制。同时在协调者和参与者中都引入超时机制；
                在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。
            canCommit preCommit doCommit
    paxos协议: 强一致性，高可用的去中心化分布式协议
        三类节点:
            1.proposer:提案者对任何操作都抽象成value，可以有多个提案者，不同的value，不过在一轮中最终只会保存一个value
            2.acceptor:批准者 。Acceptor 有 N 个，Proposer 提出的 value 必须获得超过半数(N/2+1)的 Acceptor批准后才能通过。Acceptor 之间完全对等独立。
            3.learner：学习者，学习被通过的value，至少学习过半数的accptor，至多学习全部
        流程:
            1.准备阶段 对应的是proposer处理流程
            2.批准阶段 对应的是acceptor处理流程
        并发与活锁:
            但在 Paxos 协议过程中，虽然也存在着并发竞争，不会出现上述死锁。这是因为，Paxos 协议
            引入了轮数的概念，高轮数的 paxos 提案可以抢占低轮数的 paxos 提案。从而避免了死锁的发生。
            然而这种设计却引入了“活锁”的可能，即 Proposer 相互不断以更高的轮数提出议案，使得每轮 Paxos
            过程都无法最终完成，从而无法批准任何一个 value。
    
    CAP理论:
        C:consistency 一致性 CAP 理论中的副本一致性特指强一致性
        A:availiablity 可用性 指系统在出现异常时已经可以提供服务；
        P:partition 分区容忍 指系统可以对网络分区这种异常情况进行容错处理

    Zookeeper: 属于观察者设计模式 
        zk 保证的CP
        eureka 保证的AP
        一致性协议:ZAB (Zookeeper automic broadcast) 原子广播协议 很好的支持奔溃恢复
            消息广播模式
                1.leader从客户端收到一个写请求
                2.leader生成一个新的事务并为这个事务生成一个唯一的ZXID
                3.leader将这个事务发送给所有的follows节点，将带有 zxid 的消息作为一个提案(proposal)分发给所有 follower。
                4.follower节点将收到的事务请求加入到历史队列(history queue)中，当 follower 接收到 proposal，先将 proposal 写到硬盘，写硬盘成功后再向 leader 回一个 ACK
                5.当leader收到大多数follower（超过一半）的ack消息，leader会向follower发送commit请求（leader自身也要提交这个事务）
                6.当follower收到commit请求时，会判断该事务的ZXID是不是比历史队列中的任何事务的ZXID都小，如果是则提交事务，如果不是则等待比它更小的事务的commit(保证顺序性)
                7.Leader将处理结果返回给客户端

            奔溃恢复模式
                选举、 在leader奔溃时，集群进入选举阶段，选举时会比较zxid，最新的才选出准leader
                发现、 发现最新的zxid和事务日志，准leader接受到所有的follower发来的最新epoch值，选出最大的epoch 然后加1，转发给其他follower，follower返回ack给leader，带上各自最大的zxid和历史提议日志，leader选出最大的zxid并更新历史日志，此时leader就拥有最新的提议
                同步、 通过最新的提议，同步给集群的follower，过半通过，才成为正式的leader
                广播、 恢复到广播模式

        三个角色:
            leader 唯一写请求处理者，能够发起投票
            follower 读请求自己处理 写请求转发给leader ，有选举权和被选举权
            observer 啥都没有的follower
        选举机制:
            两个阶段:
                1.leader宕机需要重新选举
                2.zkserver启动时需要进行系统leader的初始化选举
            zkserver状态:
                looking: 不确定leader，说明此时当前集群没有leader，会发起选举
                following: 当前服务角色为follower，并且知道leader是谁
                leading: 当前服务角色为leader，维护与follower的心跳
                observing: 当前角色为observer，
        zxid
            Zookeeper transaction id  64位的Long类型 全局递增的 高32位为纪元epoch 低32位为事务标识xid
        base理论:
            基本可用(basically available) 分布式系统出现故障时，允许损失部分可用性
            软状态(soft state) 软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有多个副本，允许不同节点间副本同步的延时就是软状态的体现。
            最终一致性(eventual consistency) 最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。
        zk数据模型:
            多叉树结构，每个节点都能存储数据， znode 最多存储1m
            znode类型:
                1.持久化目录节点persistent: 客户端与zk断开后，节点依旧存在
                2.持久化顺序编号目录节点persistent_sequential： 断开依旧存在，不过进行顺序编号
                3.临时目录节点ephemeral: 断开后 节点删除
                4.临时顺序目录节点: 断开后节点删除 不过只是有序而已
        
        监听通知机制:
            watcher:
                对创建的节点可以进行绑定监听事件，比如节点数据变更，节点删除，节点状态变更
            流程:
                1.首先要有一个main()线程
                2.在main线程中创建zkClient，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）。
                3.通过connect线程将注册的监听事件发送给Zookeeper。
                4.在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。
                5.Zookeeper监听到有数据或路径变化，就会将这个消息发送给listener线程。
                6.listener线程内部调用了process()方法。
        zk session:
            session可以看做zk服务器与客户端之间的一个tcp长链接，任何操作都需要session
            会话状态:
                connecting:连接中，session一但创建，状态就是这个，时间短
                connected:已连接，
                closed: 已关闭，发生崽session过期，一般由于网络故障客户端重连失败，服务器宕机或者客户端主动断开
        
        ClientCnxn:客户端核心类
            sendthread: i/o线程,主要负责zk客户端与服务端的io通信 同时还负责将来自服务端的事件传递给eventThread处理
            eventThread: 事件线程，处理客户端的事件，并触发客户端注册的watcher监听

            ClientCnxn中有两个核心队列outgoingQueue和pendingQueue，分别代表客户端的请求发送队列和服务端响应的等待队列。

        会话超时管理：
            session是由zk服务器管理的，使用分桶机制，将session分配到一个个桶里面，通过expirationTime来区分
            ExpirationTime = CurrentTime + SessionTimeout;
            ExpirationTime = (ExpirationTime / ExpirationInterval + 1) * ExpirationInterval;
            将session分散 默认 ExpirationInterval = 2000ms


        zk 分布式锁:
            利用zk临时顺序节点的特性来实现:
            首先，在Zookeeper当中创建一个持久节点ParentLock。当第一个客户端想要获得锁时，需要在ParentLock这个节点下面创建一个临时顺序节点 Lock1。
            第一个创建的时候必然是第一个，此时持有锁，第二个进来同样会创建临时节点lock2,发现自己不是最前一个，那么就给lock1注册一个watcher，进入等待
            任务完成后，会显示调用删除节点lock1，监听到那么锁释放，lock2持有锁

        zk/redis分布式锁比较:
            1.zk容易实现，有等待锁的队列，提升锁效率，但是涉及到增加删除节点 性能低
            2.redis sel del指令性能高，但是实现复杂，需要考虑超时，原子性等，没有等待锁的队列，只能自旋来等待锁，效率低

        zk引用场景:
            1.数据发布、订阅
            2.统一配置管理
            3.统一集群管理
            4.负载均衡
                ZooKeeper负载均衡和Nginx负载均衡区别：
                    ZooKeeper不存在单点问题，zab机制保证单点故障可重新选举一个leader只负责服务的注册与发现，不负责转发，减少一次数据交换（消费方与服务方直接通信），需要自己实现相应的负载均衡算法。
                    Nginx存在单点问题，单点负载高数据量大,需要通过 KeepAlived + LVS 备机实现高可用。每次负载，都充当一次中间人转发角色，增加网络负载量（消费方与服务方间接通信），自带负载均衡算法。
            5.命名服务
            6.分布式锁选举
        
        分布式一致性解决方案是state machine repalication（状态机复制）
        raft:
            1.领导者选举
            2.日志复制
            3.安全 恢复